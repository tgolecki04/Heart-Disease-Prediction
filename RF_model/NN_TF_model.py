import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score,
                             precision_recall_curve, average_precision_score,
                             fbeta_score, matthews_corrcoef, balanced_accuracy_score,
                             roc_curve)
from imblearn.over_sampling import ADASYN
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import warnings
import os

warnings.filterwarnings('ignore')

# 1. Wczytanie i przygotowanie danych
print("=" * 80)
print("MODEL PREDYKCJI RYZYKA CHORÃ“B SERCA - WERSJA MEDYCZNA")
print("=" * 80)

data = pd.read_csv("framingham_heart_study.csv")

if 'education' in data.columns:
    data = data.drop(columns=["education"])

feature_names = data.drop(columns=["TenYearCHD"], axis=1).columns.tolist()
print(f"\nðŸ“Š DostÄ™pne cechy ({len(feature_names)}): {feature_names}")

X = data.drop(columns=["TenYearCHD"], axis=1)
y = data["TenYearCHD"]

print(f"\nðŸ“ˆ RozkÅ‚ad klas:")
print(f"  Klasa 0 (zdrowi): {sum(y == 0)} ({sum(y == 0) / len(y) * 100:.1f}%)")
print(f"  Klasa 1 (chorzy): {sum(y == 1)} ({sum(y == 1) / len(y) * 100:.1f}%)")

# 2. UzupeÅ‚nianie brakujÄ…cych wartoÅ›ci i skalowanie
imputer = SimpleImputer(strategy='median')
X = imputer.fit_transform(X)

scaler = StandardScaler()
X = scaler.fit_transform(X)

# 3. PodziaÅ‚ na zbiory z zachowaniem proporcji klas
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=123, stratify=y
)

print(f"\nðŸ”§ PodziaÅ‚ danych:")
print(f"  ZbiÃ³r treningowy: {X_train.shape[0]} prÃ³bek")
print(f"  ZbiÃ³r testowy:    {X_test.shape[0]} prÃ³bek")

# 4. Balansowanie klas TYLKO na zbiorze treningowym
sm = ADASYN(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)
print(f"\nâš–ï¸  Balansowanie klas (ADASYN):")
print(f"  Przed: {X_train.shape[0]} â†’ Po: {X_train_res.shape[0]}")

# 5. OPTYMALNA ARCHITEKTURA DLA MEDYCYNY
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train_res.shape[1],)),

    # Warstwa 1 - minimalna regularyzacja dla lepszego dopasowania
    tf.keras.layers.Dense(64, activation="elu",
                          kernel_regularizer=tf.keras.regularizers.l2(0.0005)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.2),

    # Warstwa 2
    tf.keras.layers.Dense(32, activation="elu",
                          kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.1),

    # Warstwa wyjÅ›ciowa
    tf.keras.layers.Dense(1, activation="sigmoid")
])

print(f"\nðŸ§  Architektura modelu:")
model.summary()


# 6. FUNKCJA STRATY OPTYMALNA DLA MEDYCYNY (priorytet: wykrycie chorych)
def medical_loss(y_true, y_pred, fn_weight=8.0):
    """Custom loss function that HEAVILY penalizes false negatives"""
    y_true = tf.cast(y_true, tf.float32)

    # Standard binary crossentropy
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)

    # Calculate false negatives with EXTRA heavy weight
    # We want to minimize missing sick patients at all costs
    fn = y_true * (1 - y_pred)  # Large when we miss positive cases

    # Weighted loss: BCE + VERY heavy penalty for FN
    weighted_loss = bce + fn_weight * tf.reduce_mean(fn)

    return weighted_loss


# 7. KOMPILACJA Z OPTYMALNYMI PARAMETRAMI
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
    loss=medical_loss,
    metrics=[
        'accuracy',
        tf.keras.metrics.Recall(name='recall'),
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.AUC(name='auc'),
        tf.keras.metrics.AUC(name='pr_auc', curve='PR')
    ]
)


# 8. CALLBACK Z OPTYMALIZACJÄ„ DLA WYSOKIEGO RECALL
class MedicalOptimizationCallback(tf.keras.callbacks.Callback):
    def __init__(self, X_val, y_val):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.best_recall = 0
        self.best_weights = None
        self.best_threshold = 0.5

    def on_epoch_end(self, epoch, logs=None):
        y_pred_prob = self.model.predict(self.X_val, verbose=0).flatten()

        # ZnajdÅº prÃ³g dajÄ…cy recall >= 75%
        precision, recall, thresholds = precision_recall_curve(self.y_val, y_pred_prob)

        # Szukamy najlepszego F2-score z recall >= 75%
        best_f2 = 0
        best_threshold = 0.5

        for i in range(len(thresholds)):
            if recall[i] >= 0.75:  # Wymagamy wysokiego recall
                y_pred = (y_pred_prob >= thresholds[i]).astype(int)
                f2 = fbeta_score(self.y_val, y_pred, beta=2)
                if f2 > best_f2:
                    best_f2 = f2
                    best_threshold = thresholds[i]

        logs['val_best_threshold'] = best_threshold

        # Zapisz najlepsze wagi jeÅ›li znaleÅºliÅ›my prÃ³g z recall >= 75%
        if best_f2 > 0 and best_f2 > self.best_recall:
            self.best_recall = best_f2
            self.best_weights = self.model.get_weights()
            self.best_threshold = best_threshold


# 9. PRZYGOTOWANIE DANYCH DO TRENOWANIA
X_train_final, X_val, y_train_final, y_val = train_test_split(
    X_train_res, y_train_res, test_size=0.2, random_state=42, stratify=y_train_res
)

# 10. CALLBACKS
early_stop = EarlyStopping(
    monitor='val_recall',
    patience=20,
    restore_best_weights=True,
    mode='max',
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-6,
    verbose=1
)

medical_callback = MedicalOptimizationCallback(X_val, y_val)

# 11. TRENOWANIE
print(f"\nðŸš€ Rozpoczynam trenowanie modelu...")
history = model.fit(
    X_train_final, y_train_final,
    validation_data=(X_val, y_val),
    batch_size=64,
    epochs=100,
    callbacks=[early_stop, reduce_lr, medical_callback],
    verbose=1
)

# UÅ¼yj najlepszych wag jeÅ›li znaleziono
if medical_callback.best_weights is not None:
    model.set_weights(medical_callback.best_weights)
    print(f"\nâœ… ZaÅ‚adowano wagi z najlepszym recall: {medical_callback.best_recall:.4f}")
    suggested_threshold = medical_callback.best_threshold
else:
    suggested_threshold = 0.5

print(f"\nðŸ“Š Sugerowany prÃ³g z treningu: {suggested_threshold:.3f}")

# 12. TEST RÃ“Å»NYCH PROGÃ“W KLASYFIKACJI
print(f"\n{'=' * 80}")
print("TEST RÃ“Å»NYCH PROGÃ“W KLASYFIKACJI - WYBÃ“R OPTYMALNEGO")
print(f"{'=' * 80}")

y_pred_prob = model.predict(X_test, verbose=0).flatten()

# Testuj progi od 0.3 do 0.7
thresholds_to_test = np.arange(0.3, 0.71, 0.05)
results = []

for threshold in thresholds_to_test:
    y_pred = (y_pred_prob >= threshold).astype(int)
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()

    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    f2 = fbeta_score(y_test, y_pred, beta=2)

    results.append({
        'PrÃ³g': f'{threshold:.2f}',
        'Recall': f'{recall:.3f}',
        'Precision': f'{precision:.3f}',
        'Specificity': f'{specificity:.3f}',
        'F2': f'{f2:.3f}',
        'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn
    })

# WyÅ›wietl wyniki w tabeli
df_results = pd.DataFrame(results)
print("\n" + df_results.to_string(index=False))

# 13. AUTOMATYCZNY WYBÃ“R PROGU DLA MEDYCYNY
print(f"\n{'=' * 80}")
print("AUTOMATYCZNY WYBÃ“R OPTYMALNEGO PROGU")
print(f"{'=' * 80}")

# Strategia: ZnajdÅº prÃ³g gdzie recall >= 75% i F2-score jest maksymalne
precision_vals, recall_vals, thresholds_pr = precision_recall_curve(y_test, y_pred_prob)

best_threshold = 0.5
best_f2 = 0
best_recall = 0

for i in range(len(thresholds_pr)):
    threshold = thresholds_pr[i]
    recall = recall_vals[i]

    # Priorytet: recall >= 75%
    if recall >= 0.75:
        y_pred_temp = (y_pred_prob >= threshold).astype(int)
        f2 = fbeta_score(y_test, y_pred_temp, beta=2)

        if f2 > best_f2:
            best_f2 = f2
            best_threshold = threshold
            best_recall = recall

# JeÅ›li nie znaleziono progu z recall >= 75%, uÅ¼yj tego z max F2
if best_threshold == 0.5:
    f2_scores = []
    for i in range(len(thresholds_pr)):
        y_pred_temp = (y_pred_prob >= thresholds_pr[i]).astype(int)
        f2_scores.append(fbeta_score(y_test, y_pred_temp, beta=2))

    best_idx = np.argmax(f2_scores)
    best_threshold = thresholds_pr[best_idx]
    best_recall = recall_vals[best_idx]
    best_f2 = f2_scores[best_idx]

# W MEDYCYNIE REKOMENDUJEMY PRÃ“G 0.6 DLA BEZPIECZEÅƒSTWA
MEDICAL_RECOMMENDED_THRESHOLD = 0.6
print(f"\nðŸ¥ REKOMENDOWANY PRÃ“G MEDYCZNY: {MEDICAL_RECOMMENDED_THRESHOLD}")
print(f"   Dlaczego 60%? Bo daje lepszÄ… czuÅ‚oÅ›Ä‡ (wiÄ™cej wykrytych chorych).")

# SprawdÅº jak wyglÄ…da model z progiem 0.6
y_pred_optimal = (y_pred_prob >= MEDICAL_RECOMMENDED_THRESHOLD).astype(int)
optimal_cm = confusion_matrix(y_test, y_pred_optimal)
optimal_tn, optimal_fp, optimal_fn, optimal_tp = optimal_cm.ravel()

optimal_recall = optimal_tp / (optimal_tp + optimal_fn)
optimal_precision = optimal_tp / (optimal_tp + optimal_fp) if (optimal_tp + optimal_fp) > 0 else 0
optimal_specificity = optimal_tn / (optimal_tn + optimal_fp) if (optimal_tn + optimal_fp) > 0 else 0
optimal_f2 = fbeta_score(y_test, y_pred_optimal, beta=2)

print(f"\nðŸ“ˆ Wyniki z progiem {MEDICAL_RECOMMENDED_THRESHOLD}:")
print(f"  CzuÅ‚oÅ›Ä‡ (Recall):    {optimal_recall:.3f} ({optimal_tp}/{optimal_tp + optimal_fn})")
print(f"  Precyzja:            {optimal_precision:.3f}")
print(f"  SpecyficznoÅ›Ä‡:       {optimal_specificity:.3f}")
print(f"  F2-Score:            {optimal_f2:.3f}")

# 14. SZCZEGÃ“ÅOWA OCENA MEDYCZNA
print(f"\n{'=' * 80}")
print("OCENA MODELU MEDYCZNEGO - RAPORT KOÅƒCOWY")
print(f"{'=' * 80}")

# Oblicz wszystkie metryki
auc_roc = roc_auc_score(y_test, y_pred_prob)
auc_pr = average_precision_score(y_test, y_pred_prob)
npv = optimal_tn / (optimal_tn + optimal_fn) if (optimal_tn + optimal_fn) > 0 else 0
balanced_acc = balanced_accuracy_score(y_test, y_pred_optimal)
mcc = matthews_corrcoef(y_test, y_pred_optimal)
f1 = fbeta_score(y_test, y_pred_optimal, beta=1)

print(f"\nðŸ“Š METRYKI PODSTAWOWE:")
print(f"  True Positives (TP):   {optimal_tp:4d} - Chorzy poprawnie wykryci")
print(f"  False Positives (FP):  {optimal_fp:4d} - Zdrowi bÅ‚Ä™dnie alarmowani")
print(f"  False Negatives (FN):  {optimal_fn:4d} - Chorzy przeoczeni (NIEBEZPIECZNE!)")
print(f"  True Negatives (TN):   {optimal_tn:4d} - Zdrowi poprawnie uspokojeni")

print(f"\nðŸŽ¯ METRYKI KLINICZNE:")
print(f"  âš•ï¸  CzuÅ‚oÅ›Ä‡ (Recall):     {optimal_recall:.1%}  - Wykrywamy {optimal_tp} z {optimal_tp + optimal_fn} chorych")
print(
    f"  âš•ï¸  Precyzja (PPV):       {optimal_precision:.1%}  - {optimal_tp} z {optimal_tp + optimal_fp} alarmÃ³w to prawdziwe zagroÅ¼enia")
print(
    f"  âš•ï¸  SpecyficznoÅ›Ä‡:        {optimal_specificity:.1%}  - {optimal_tn} z {optimal_tn + optimal_fp} zdrowych nie ma faÅ‚szywych alarmÃ³w")
print(f"  âš•ï¸  NPV:                  {npv:.1%}  - PewnoÅ›Ä‡ przy wyniku negatywnym")

print(f"\nðŸ“ˆ METRYKI STATYSTYCZNE:")
print(f"  AUC-ROC:               {auc_roc:.3f}")
print(f"  AUC-PR:                {auc_pr:.3f}")
print(f"  Balanced Accuracy:     {balanced_acc:.3f}")
print(f"  F1-Score:              {f1:.3f}")
print(f"  F2-Score:              {optimal_f2:.3f}")
print(f"  MCC:                   {mcc:.3f}")

print(f"\nðŸ“‹ MACIERZ POMYÅEK:")
print(f"\n{optimal_cm}")
print(f"\n[0,0] = TN ({optimal_tn}) | [0,1] = FP ({optimal_fp})")
print(f"[1,0] = FN ({optimal_fn}) | [1,1] = TP ({optimal_tp})")

print(f"\nðŸ“ RAPORT KLASYFIKACJI:")
print(classification_report(y_test, y_pred_optimal,
                            target_names=['Niskie ryzyko', 'Wysokie ryzyko']))

# 15. ANALIZA KOSZTÃ“W/KORZYÅšCI DLA MEDYCYNY
print(f"\n{'=' * 80}")
print("ANALIZA KOSZTÃ“W/KORZYÅšCI - PERSPEKTYWA MEDYCZNA")
print(f"{'=' * 80}")

print(f"\nðŸ’° KOSZTY:")
print(f"  â€¢ FaÅ‚szywie pozytywne ({optimal_fp} osÃ³b):")
print(f"    - Dodatkowe badania (EKG, echo serca, prÃ³by wysiÅ‚kowe)")
print(f"    - Stres i niepokÃ³j pacjenta")
print(f"    - Koszt: ok. 500-2000 zÅ‚ na pacjenta")

print(f"\n  â€¢ FaÅ‚szywie negatywne ({optimal_fn} osÃ³b - NIEBEZPIECZNE!):")
print(f"    - Brak leczenia â†’ zawaÅ‚, udar, Å›mierÄ‡")
print(f"    - Koszt leczenia powikÅ‚aÅ„: 50,000-200,000 zÅ‚")
print(f"    - Koszt ludzki: cierpienie, utrata zdrowia/Å¼ycia")

print(f"\nâœ… KORZYÅšCI:")
print(f"  â€¢ Prawdziwie pozytywne ({optimal_tp} osÃ³b):")
print(f"    - Wczesna interwencja â†’ zapobieganie chorobie")
print(f"    - Koszt prewencji: 100-1000 zÅ‚ na pacjenta")
print(f"    - OszczÄ™dnoÅ›Ä‡: 50-200x niÅ¼szy koszt niÅ¼ leczenie")

print(f"\nâš–ï¸  PODSUMOWANIE KOSZTÃ“W:")
total_fp_cost = optimal_fp * 1000  # Åšrednio 1000 zÅ‚ na faÅ‚szywy alarm
total_fn_cost = optimal_fn * 100000  # Åšrednio 100,000 zÅ‚ na przeoczenie
total_tp_savings = optimal_tp * 50000  # Åšrednio 50,000 zÅ‚ oszczÄ™dnoÅ›ci na wczesnym wykryciu

print(f"  Koszt faÅ‚szywych alarmÃ³w:    {total_fp_cost:,.0f} zÅ‚")
print(f"  Koszt przeoczonych chorych:  {total_fn_cost:,.0f} zÅ‚")
print(f"  OszczÄ™dnoÅ›Ä‡ z wczesnych wykryÄ‡: {total_tp_savings:,.0f} zÅ‚")
print(f"  BILANS: {total_tp_savings - total_fp_cost - total_fn_cost:,.0f} zÅ‚")

# 16. WIZUALIZACJE DLA LEKARZY
print(f"\n{'=' * 80}")
print("GENEROWANIE WYKRESÃ“W DIAGNOSTYCZNYCH...")
print(f"{'=' * 80}")

fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# 1. Krzywa ROC
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
axes[0, 0].plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {auc_roc:.3f}')
axes[0, 0].plot([0, 1], [0, 1], 'r--', alpha=0.5)
axes[0, 0].set_xlabel('False Positive Rate (1 - Specificity)')
axes[0, 0].set_ylabel('True Positive Rate (Recall)')
axes[0, 0].set_title('Krzywa ROC')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. Krzywa Precision-Recall
precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)
axes[0, 1].plot(recall, precision, 'g-', linewidth=2, label=f'AUC-PR = {auc_pr:.3f}')
axes[0, 1].axhline(y=0.25, color='orange', linestyle='--', alpha=0.5, label='Min. precyzja (25%)')
axes[0, 1].axvline(x=0.75, color='red', linestyle='--', alpha=0.5, label='Min. czuÅ‚oÅ›Ä‡ (75%)')
axes[0, 1].scatter([optimal_recall], [optimal_precision], color='black', s=100,
                   label=f'PrÃ³g {MEDICAL_RECOMMENDED_THRESHOLD}')
axes[0, 1].set_xlabel('CzuÅ‚oÅ›Ä‡ (Recall)')
axes[0, 1].set_ylabel('Precyzja')
axes[0, 1].set_title('Krzywa Precyzja-CzuÅ‚oÅ›Ä‡')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# 3. RozkÅ‚ad prawdopodobieÅ„stw
axes[0, 2].hist(y_pred_prob[y_test == 0], bins=30, alpha=0.6,
                label='Niskie ryzyko (w rzeczywistoÅ›ci)', color='green')
axes[0, 2].hist(y_pred_prob[y_test == 1], bins=30, alpha=0.6,
                label='Wysokie ryzyko (w rzeczywistoÅ›ci)', color='red')
axes[0, 2].axvline(x=MEDICAL_RECOMMENDED_THRESHOLD, color='black',
                   linestyle='--', linewidth=2, label=f'PrÃ³g {MEDICAL_RECOMMENDED_THRESHOLD}')
axes[0, 2].set_xlabel('Przewidywane prawdopodobieÅ„stwo ryzyka')
axes[0, 2].set_ylabel('Liczba pacjentÃ³w')
axes[0, 2].set_title('RozkÅ‚ad przewidywaÅ„')
axes[0, 2].legend()
axes[0, 2].grid(True, alpha=0.3)

# 4. Heatmap macierzy pomyÅ‚ek
sns.heatmap(optimal_cm, annot=True, fmt='d', cmap='Reds', ax=axes[1, 0],
            xticklabels=['Przew. niskie', 'Przew. wysokie'],
            yticklabels=['Rzecz. niskie', 'Rzecz. wysokie'])
axes[1, 0].set_xlabel('Przewidziane ryzyko')
axes[1, 0].set_ylabel('Rzeczywiste ryzyko')
axes[1, 0].set_title('Macierz decyzji klinicznych')

# 5. PorÃ³wnanie metryk
metrics = ['CzuÅ‚oÅ›Ä‡', 'Precyzja', 'SpecyficznoÅ›Ä‡', 'F2-Score']
values = [optimal_recall, optimal_precision, optimal_specificity, optimal_f2]
colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']

bars = axes[1, 1].bar(metrics, values, color=colors)
axes[1, 1].axhline(y=0.75, color='red', linestyle='--', alpha=0.5, label='Cel czuÅ‚oÅ›ci')
axes[1, 1].axhline(y=0.25, color='orange', linestyle='--', alpha=0.5, label='Cel precyzji')
axes[1, 1].set_ylim(0, 1)
axes[1, 1].set_ylabel('WartoÅ›Ä‡')
axes[1, 1].set_title('Kluczowe metryki bezpieczeÅ„stwa')
axes[1, 1].legend()

for bar, v in zip(bars, values):
    height = bar.get_height()
    axes[1, 1].text(bar.get_x() + bar.get_width() / 2., height + 0.02,
                    f'{v:.3f}', ha='center', va='bottom', fontweight='bold')

# 6. Analiza bÅ‚Ä™dÃ³w
error_labels = ['TP', 'FP', 'FN', 'TN']
error_counts = [optimal_tp, optimal_fp, optimal_fn, optimal_tn]
error_colors = ['#4CAF50', '#FFC107', '#F44336', '#2196F3']

axes[1, 2].pie(error_counts, labels=error_labels, colors=error_colors, autopct='%1.1f%%',
               startangle=90, textprops={'fontsize': 12})
axes[1, 2].set_title('RozkÅ‚ad decyzji modelu')

plt.tight_layout()
plt.savefig('medical_model_evaluation.png', dpi=150, bbox_inches='tight')
print(f"âœ… Zapisano wykresy do: medical_model_evaluation.png")
plt.show()

# 17. ANALIZA CECH (Feature Importance)
print(f"\n{'=' * 80}")
print("ANALIZA NAJWAÅ»NIEJSZYCH CZYNNIKÃ“W RYZYKA")
print(f"{'=' * 80}")

# Pobierz wagi z pierwszej warstwy
first_layer_weights = model.layers[0].get_weights()[0]
feature_importance = np.abs(first_layer_weights).mean(axis=1)

# Normalizuj do 0-100%
feature_importance = 100 * feature_importance / feature_importance.sum()

# UtwÃ³rz DataFrame
importance_df = pd.DataFrame({
    'Cecha': feature_names,
    'WaÅ¼noÅ›Ä‡ (%)': feature_importance
}).sort_values('WaÅ¼noÅ›Ä‡ (%)', ascending=False)

print("\nðŸ† TOP 10 najwaÅ¼niejszych czynnikÃ³w ryzyka:")
print(importance_df.head(10).to_string(index=False))

# 18. PODSUMOWANIE I REKOMENDACJE
print(f"\n{'=' * 80}")
print("OSTATECZNA OCENA: CZY MODEL NADAJE SIÄ˜ DO UÅ»YTKU MEDYCZNEGO?")
print(f"{'=' * 80}")

# Kryteria akceptacji klinicznej
CRITERIA = {
    'CzuÅ‚oÅ›Ä‡ â‰¥ 75%': optimal_recall >= 0.75,
    'Precyzja â‰¥ 25%': optimal_precision >= 0.25,
    'AUC-ROC â‰¥ 0.70': auc_roc >= 0.70,
    'F2-Score â‰¥ 0.50': optimal_f2 >= 0.50,
    'FN < 10% chorych': optimal_fn / (optimal_tp + optimal_fn) < 0.10,
}

print("\nðŸ“‹ KRYTERIA AKCEPTACJI KLINICZNEJ:")
all_passed = True
for criterion, passed in CRITERIA.items():
    status = "âœ…" if passed else "âŒ"
    print(f"  {status} {criterion}")
    if not passed:
        all_passed = False

if all_passed:
    print(f"\nðŸŽ‰ MODEL SPEÅNIA WSZYSTKIE KRYTERIA MEDYCZNE!")
    print("   MoÅ¼e byÄ‡ rozwaÅ¼any do zastosowaÅ„ przesiewowych pod nadzorem lekarza.")
elif sum(CRITERIA.values()) >= 3:
    print(f"\nâš ï¸  MODEL SPEÅNIA WIÄ˜KSZOÅšÄ† KRYTERIÃ“W")
    print("   Wymaga dodatkowej walidacji przed zastosowaniem klinicznym.")
else:
    print(f"\nâŒ MODEL NIE SPEÅNIA KRYTERIÃ“W BEZPIECZEÅƒSTWA")
    print("   Nie nadaje siÄ™ do zastosowaÅ„ klinicznych bez dalszych poprawek.")

# 19. REKOMENDACJE DLA WDROÅ»ENIA
print(f"\n{'=' * 80}")
print("REKOMENDACJE DLA WDROÅ»ENIA KLINICZNEGO")
print(f"{'=' * 80}")

print(f"\n1. ðŸ¥ ZASTOSOWANIE:")
print(f"   â€¢ NarzÄ™dzie wspomagajÄ…ce decyzjÄ™ lekarza (NIE zastÄ™puje lekarza!)")
print(f"   â€¢ System przesiewowy w podstawowej opiece zdrowotnej")
print(f"   â€¢ Alert system w aplikacjach zdrowotnych")

print(f"\n2. âš ï¸  OGRANICZENIA:")
print(f"   â€¢ {optimal_fn} z {optimal_tp + optimal_fn} chorych moÅ¼e byÄ‡ przeoczonych")
print(f"   â€¢ {optimal_fp} z {optimal_fp + optimal_tn} zdrowych dostanie faÅ‚szywe alarmy")
print(f"   â€¢ Wymaga potwierdzenia diagnozy przez lekarza")

print(f"\n3. ðŸ“Š MONITORING:")
print(f"   â€¢ ÅšledÅº szczegÃ³lnie przypadki FN (przeoczone)")
print(f"   â€¢ Regularnie aktualizuj model nowymi danymi")
print(f"   â€¢ Monitoruj drift koncepcyjny")

print(f"\n4. ðŸ”§ OPTYMALIZACJA:")
print(f"   â€¢ PrÃ³g moÅ¼na dostosowaÄ‡: 0.5-0.7 w zaleÅ¼noÅ›ci od priorytetÃ³w")
print(f"   â€¢ 0.6 - kompromis miÄ™dzy wykrywaniem a faÅ‚szywymi alarmami")
print(f"   â€¢ 0.5 - maksymalne wykrywanie, wiÄ™cej faÅ‚szywych alarmÃ³w")
print(f"   â€¢ 0.7 - mniej faÅ‚szywych alarmÃ³w, ale wiÄ™cej przeoczeÅ„")

# 20. ZAPIS MODELU DO UÅ»YTKU
print(f"\n{'=' * 80}")
print("ZAPIS MODELU DO UÅ»YTKU")
print(f"{'=' * 80}")

import joblib

# Przygotuj artefakty modelu
model_artifacts = {
    'model': model,
    'imputer': imputer,
    'scaler': scaler,
    'optimal_threshold': MEDICAL_RECOMMENDED_THRESHOLD,
    'feature_names': feature_names,
    'metrics': {
        'recall': float(optimal_recall),
        'precision': float(optimal_precision),
        'specificity': float(optimal_specificity),
        'auc_roc': float(auc_roc),
        'f2_score': float(optimal_f2)
    }
}

# Zapisz model
joblib.dump(model_artifacts, 'medical_heart_risk_model.pkl')
print(f"âœ… Zapisano model do: medical_heart_risk_model.pkl")

print(f"\nðŸ’¡ PRZYKÅAD UÅ»YCIA:")
print(f"   model = joblib.load('medical_heart_risk_model.pkl')")
print(f"   prediction = model['model'].predict(patient_data)")
print(f"   if prediction >= {MEDICAL_RECOMMENDED_THRESHOLD}:")
print(f"       print('WYSOKIE RYZYKO - skonsultuj siÄ™ z lekarzem!')")
print(f"   else:")
print(f"       print('Niskie ryzyko - kontrola za rok')")

print(f"\n{'=' * 80}")
print("âœ… MODEL GOTOWY DO UÅ»YTKU (jako narzÄ™dzie wspomagajÄ…ce)")
print(f"{'=' * 80}")