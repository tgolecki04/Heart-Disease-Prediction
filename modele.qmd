---
title: "Wczesne Wykrywanie Ryzyka Zawału Serca"
subtitle: "Modele Predykcyjne"
format: html
editor: visual
---

### Model 1: Random Forest (Las Losowy)

Random Forest to zespołowy algorytm uczenia maszynowego oparty na konstrukcji wielu drzew decyzyjnych (200 w tym przypadku). Każde drzewo uczone jest na losowej podpróbie danych z losowym podzbiorem cech, a ostateczna predykcja wynika z głosowania większościowego. Wybór tego modelu motywowany był jego odpornością na przeuczenie, zdolnością do modelowania nieliniowych zależności oraz wbudowaną estymacją ważności cech.

Preprocessing obejmował usunięcie cechy 'education', imputację medianą braków danych, stratęfikowany podział danych (80:20) oraz zastosowanie SMOTE do balansowania klas. Wyniki wykazały umiarkowaną zdolność dyskryminacyjną (AUC = 0,668). Model osiągnął wysoką specyficzność (94%) ale krytycznie niską czułość (16%), co oznaczało, że wykrywał jedynie 16% osób z rzeczywistym ryzykiem choroby. W praktyce klinicznej 84% chorych zostałoby fałszywie uspokojonych, co jest niedopuszczalne w prewencji.

Mocne strony modelu to stabilność i mała podatność na przeuczenie oraz poprawna metodologia preprocessingu. Główną wadą była katastrofalnie niska czułość, spowodowana domyślną optymalizacją dokładności w niezbalansowanych danych.

### Model 2: XGBoost bez SMOTE

XGBoost to zaawansowany algorytm gradient boosting, który buduje sekwencyjnie drzewa decyzyjne, gdzie każde kolejne drzewo koryguje błędy poprzednich. Kluczową innowacją było zastosowanie parametru `scale_pos_weight = 5,58`, który zwiększał koszt błędnej klasyfikacji przypadków pozytywnych, zmuszając model do większej uwagi na klasę mniejszościową.

Model osiągnął AUC = 0,659. Wykazał radykalnie inną charakterystykę niż Random Forest: czułość wyniosła 50% (ponad 3-krotna poprawa), ale precyzja spadła do 26%. Oznaczało to, że model wykrywał połowę osób z ryzykiem, ale tylko 26% oznaczeń "grupa ryzyka" było prawdziwych. Wzrost czułości osiągnięto więc kosztem dużej liczby fałszywych alarmów (74%).

Główną siłą tego modelu było celowanie w kluczową metrykę kliniczną - czułość, co jest priorytetem w badaniach przesiewowych. Wadą pozostała niska precyzja, prowadząca do niepotrzebnego stresu i kosztów diagnostycznych dla wielu zdrowych osób.

### Model 3: XGBoost z SMOTE

Model 3 stanowił hybrydowe podejście, łączące SMOTE (oversampling syntetyczny) z parametrem `scale_pos_weight`. Celem było sprawdzenie, czy połączenie obu metod da lepsze wyniki niż zastosowanie każdej z nich osobno.

Wyniki pokazały negatywny efekt synergii: AUC spadło do 0,639 (najniższa wartość). Model osiągnął rekordowy recall (60%) przy katastrofalnej precyzji (20%) - tylko 1 na 5 alarmów był prawdziwy. Jednocześnie recall dla klasy 0 spadł do 57%, co oznaczało, że 43% zdrowych pacjentów było błędnie straszonych pozytywnym wynikiem.

Model ten okazał się przykładem anty-wzoru, pokazując jak nieumiejętne łączenie technik może pogorszyć wydajność. Podwójna korekta niezbalansowania prowadziła do nadmiernego dopasowania do klasy mniejszościowej i utraty podstawowej użyteczności jako narzędzie przesiewowe.

### Model 4: Prosta Sieć Neuronowa (MLP)

MLP to klasyczna sieć neuronowa typu feedforward, zdolna do uczenia nieliniowych przekształceń danych poprzez warstwy ukryte z funkcjami aktywacji ReLU. Architektura obejmowała dwie warstwy ukryte (32, 16 neuronów) z manualnym ustawieniem niskiego progu klasyfikacji (threshold=0,2) w celu zwiększenia czułości.

Niestety, model zawierał poważny błąd metodologiczny - imputację braków na całym zbiorze przed podziałem, co powodowało wyciek informacji i unieważniało wiarygodność wyników. Pomimo tego, wyniki pokazały wzorzec ekstremalny: czułość 61% przy precyzji jedynie 21%. Model osiągał wysoką czułość, ale kosztem najgorszych możliwych wartości precyzji i recall dla klasy zdrowej.

ConvergenceWarning wskazywał, że proces uczenia nie osiągnął zbieżności w 320 iteracjach. W obecnej formie model był bezużyteczny z powodu błędów metodologicznych i nieprzemyślanej architektury.

### Model 5: Zaawansowana Sieć Neuronowa (TensorFlow/Keras)

Model 5 reprezentował najbardziej zaawansowane podejście z wykorzystaniem głębokiej sieci neuronowej w TensorFlow/Keras. Architektura obejmowała warstwy BatchNormalization, regularyzację L2, Dropout oraz niestandardową funkcję straty `medical_loss` z parametrem `fn_weight=6,0`, celowo karzącą fałszywie negatywne prognozy.

Mimo profesjonalnej architektury i zaawansowanych technik (ADASYN, early stopping, redukcja learning rate), model zawierał fundamentalny błąd - imputację i skalowanie na całym zbiorze przed podziałem. Wyniki były szokujące: czułość 90% (najlepsza w projekcie) przy precyzji jedynie 17% i recall klasy 0 wynoszącym zaledwie 21%. Model działał na zasadzie "oznacz wszystkich jako chorych", generując 83% fałszywych alarmów.

Paradoksalnie, najbardziej zaawansowany model okazał się najbardziej rozczarowujący, pokazując że nawet wyrafinowane techniki nie zastąpią czystego, poprawnego pipeline'u danych.

### Wnioski i Podsumowanie

Analiza pięciu modeli predykcyjnych do wczesnego wykrywania ryzyka chorób serca na podstawie danych Framingham pozwoliła wyciągnąć kluczowe wnioski:

1.  **Żaden z przedstawionych modeli w obecnej formie nie nadaje się do bezpośredniego zastosowania klinicznego** w badaniach przesiewowych. Każdy posiadał krytyczne wady: zbyt niską czułość (Random Forest), zbyt niską precyzję (XGBoost) lub fundamentalne błędy metodologiczne (sieci neuronowe).

2.  **XGBoost bez SMOTE okazał się najbardziej zrównoważonym modelem**, oferując akceptowalny kompromis między czułością (50%) a specyficznością (75%). Jego główną zaletą było świadome wykorzystanie parametru `scale_pos_weight` do celowania w kluczową metrykę kliniczną.

3.  **Problemy metodologiczne były powszechne** - szczególnie data leakage w przypadku sieci neuronowych, co całkowicie unieważniało wyniki tych modeli i podkreślało znaczenie czystego pipeline'u danych.

4.  **Kompromis między czułością a precyzją jest nieunikniony** w zadaniach medycznych z niezbalansowanymi danymi. Wybór optymalnego punktu na krzywej Precision-Recall powinien być podyktowany kosztami klinicznymi błędów.

5.  **Złożoność modelu nie gwarantuje lepszych wyników** - najprostsze modele (XGBoost, Random Forest) dały bardziej zrównoważone wyniki niż skomplikowane sieci neuronowe.

Rekomendacje na przyszłość obejmują: naprawę błędów metodologicznych (przede wszystkim data leakage), implementację dwustopniowego systemu przesiewowego łączącego model wysokiej czułości z modelem wysokiej specyficzności, strojenie hiperparametrów z wykorzystaniem metryk klinicznych (F2-score) oraz rygorystyczną walidację zewnętrzną z porównaniem do złotego standardu (skala Framingham).
